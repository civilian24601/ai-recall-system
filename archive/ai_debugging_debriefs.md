# ğŸ“„ AI Debugging Debrief Format  

## **ğŸ“Œ Overview**

This document defines the **standardized debugging debrief process** used by the AI Recall System.  

ğŸš€ **Primary Goals:**  
âœ… **Ensure AI logs debugging issues, solutions, and outcomes consistently.**  
âœ… **Enable AI to retrieve past debugging sessions from ChromaDB.**  
âœ… **Allow AI to refine its problem-solving methods over time.**  

ğŸ“Œ **AI debugging debriefs ensure system self-improvement and prevent repeated troubleshooting cycles.**  

---

## **ğŸ“Œ 1. AI Debugging Workflow**  

ğŸ“Œ **AI follows a structured workflow when debugging issues:**  

| **Stage** | **Process** |
|-----------|------------|
| **Stage 1: Error Detection** | AI detects failure & logs details into `debug_logs.json`. |
| **Stage 2: Debugging Recall** | AI queries ChromaDB (collection="debugging_logs") for past debugging attempts. |
| **Stage 3: Solution Suggestion** | AI suggests the most relevant past fix. |
| **Stage 4: Fix Execution** | AI applies or recommends a fix (depending on user preference). |
| **Stage 5: Validation & Learning** | AI evaluates the success of the applied fix and updates knowledge. |

ğŸš€ **Goal:** AI **retrieves and applies past solutions before generating new debugging workflows.**  

---

## **ğŸ“Œ 2. AI Debugging Log Format**  

ğŸ“Œ **AI stores debugging logs in `debug_logs.json` for retrieval & analysis.**  

### **ğŸ”¹ Standard Debugging Log Entry**  

```json
{
    "timestamp": "2025-02-10 14:23:11",
    "error": "SQL Integrity Constraint Violation",
    "stack_trace": "File 'db_handler.py', line 42, in execute_query...",
    "fix_attempted": "Added unique constraint to the schema.",
    "fix_successful": true,
    "ai_confidence_score": 0.95
}
âœ… Ensures debugging logs capture issue details, attempted solutions, and success rates.

ğŸ“Œ 3. AI Debugging Retrieval & Solution Matching
ğŸ“Œ AI queries ChromaDB to retrieve past debugging sessions before generating new fixes.

ğŸ”¹ ChromaDB Debugging Query Example

def retrieve_debugging_logs(error_message: str) -> list:
    """
    Queries ChromaDB for past debugging logs related to the given error message.

    Args:
        error_message (str): Error description to search for.

    Returns:
        list: Matching debugging log entries.
    """
    query = f"SELECT * FROM debug_logs WHERE error LIKE '%{error_message}%'"
    return query_chroma_db(query)
âœ… Allows AI to reuse past debugging attempts instead of starting from scratch.

ğŸ“Œ 4. AI Debugging Debrief Template
ğŸ“Œ AI automatically generates a debugging debrief after resolving an issue.

ğŸ”¹ Standard AI Debugging Debrief Format
ğŸ”¹ Task Name: [Brief Description of Debugging Task]
ğŸ”¹ Files Modified: [List of modified files]
ğŸ”¹ Functions Edited: [List of changed functions]
ğŸ”¹ Error Logs: [Stack trace & debugging details]
ğŸ”¹ AI Debugging Summary: [Steps taken, solutions attempted, and failures encountered]

âœ… Ensures AI debugging memory is structured and retrievable for future reference.

ğŸ“Œ 5. AI Debugging Evaluation & Learning
ğŸ“Œ After applying a fix, AI evaluates its effectiveness to refine future debugging suggestions.

ğŸ”¹ AI Debugging Evaluation Metrics
Metric Purpose
Solution Reuse Rate Measures how often a past fix successfully resolves a new issue.
Fix Success Rate Tracks the percentage of debugging attempts that resolved the issue.
AI Confidence Score AI assigns a confidence level to suggested fixes.
Self-Validation Accuracy AI checks if applied fixes align with stored debugging history.
ğŸš€ Goal: AI continuously improves debugging recall and solution accuracy.

ğŸ“Œ 6. AI Debugging Validation & Testing
ğŸ“Œ Ensuring AI debugging recall & execution is accurate and reliable.

âœ… Test Case 1: Debugging Recall Accuracy
ğŸ“Œ Test Goal: Ensure AI retrieves past debugging logs accurately.
ğŸ”¹ Test Command:

ai-debug "Retrieve last 3 debugging sessions."
âœ… Pass Criteria:

AI retrieves 3 relevant past debugging logs.
AI response matches previously stored error resolutions.
âœ… Test Case 2: AI-Suggested Fix Accuracy
ğŸ“Œ Test Goal: Ensure AI suggests previously applied fixes when debugging similar issues.
ğŸ”¹ Test Command:


ai-debug "Suggest a fix for a database integrity error."
âœ… Pass Criteria:

AI retrieves past solutions from ChromaDB.
AI suggests a fix with a high confidence score.
âœ… Test Case 3: AI Self-Debugging Execution
ğŸ“Œ Test Goal: AI detects, retrieves, and executes debugging solutions autonomously.
ğŸ”¹ Future AI Behavior:
1ï¸âƒ£ AI detects an error in api_structure.py.
2ï¸âƒ£ AI queries ChromaDB for past fixes.
3ï¸âƒ£ AI applies the retrieved solution autonomously.

âœ… Pass Criteria:

AI executes debugging steps without human intervention.
AI verifies the fix before marking the issue as resolved.
ğŸ“Œ Summary
ğŸ“Œ This document defines the AI debugging debriefing strategy for:
âœ… Structured debugging log storage & retrieval via ChromaDB
âœ… AI-assisted debugging recall and solution application
âœ… AI self-evaluation for debugging optimization
âœ… Standardized debugging debrief format for long-term AI learning

ğŸ“… Last Updated: February 2025
ğŸ”¹ Maintained by AI Recall System

## Updated Section: Integration with Blueprint Execution Logs

We can optionally track certain fields from blueprint_execution.py (e.g. 'efficiency_score', 'task_name') in our debug logs. 
Likewise, 'ai_confidence_score' (from debugging attempts) can be stored in execution logs for cross-analysis.

Example Combined Fields:
- timestamp, error/stack_trace, fix_attempted, fix_successful
- efficiency_score (or performance_score)
- potential_breakage_risk
- improvement_suggestions

## Additional Note: ChromaDB Integration
For long-term recall, we store structured debugging logs in the 'debugging_logs' collection. 
Scripts like 'query_chroma.py' provide convenience functions (list_debugging_logs, etc.) 
to verify or retrieve past debugging attempts.

## Updated Section: Strategy vs. Fix Logs
'debugging_strategy.py' adds a layer of "strategy" tracking on top of per-issue "fix" logs.
We can unify fields like error_type, fix_attempted, and success_rate to maintain consistent data
between 'debug_logs.json' and 'debugging_strategy_log.json'.
